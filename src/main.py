import sys
from antlr4 import FileStream, CommonTokenStream
from src.lexer.MyLangLexer import MyLangLexer
from src.parser.MyLangParser import MyLangParser
from src.AST.ASTBuilder import ASTBuilder
from src.semantic.semantic_analyzer import SemanticAnalyzer
from src.IR.ir_generator import IRGenerator
from src.optimizer.ir_optimizer import IROptimizer
from src.Nasm.nasm_generator import NASMGenerator
import os


def compile_source(source_file: str, output_file: str):
    print(f"üîß –ö–æ–º–ø–∏–ª—è—Ü–∏—è —Ñ–∞–π–ª–∞: {source_file}")

    # 1. –õ–µ–∫—Å–µ—Ä –∏ –ø–∞—Ä—Å–µ—Ä
    input_stream = FileStream(source_file, encoding="utf-8")
    lexer = MyLangLexer(input_stream)
    token_stream = CommonTokenStream(lexer)
    parser = MyLangParser(token_stream)
    tree = parser.program()

    # 2. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ AST
    ast = ASTBuilder().visit(tree)
    print("‚úÖ AST –ø–æ—Å—Ç—Ä–æ–µ–Ω–æ")

    # 3. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
    SemanticAnalyzer().analyze(ast)
    print("‚úÖ –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–π–¥–µ–Ω")

    # 4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è IR
    ir = IRGenerator().generate(ast)
    print("‚úÖ IR —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω")

    # 5. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è IR
    optimized_ir = IROptimizer().optimize(ir)
    print("‚úÖ IR –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω")

    # 6. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è NASM
    nasm_code = NASMGenerator().generate(optimized_ir)
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(nasm_code)
    print(f"‚úÖ NASM-–∫–æ–¥ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {output_file}")


if __name__ == "__main__":
    if len(sys.argv) < 3:
        print("‚ùó –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python main.py <–≤—Ö–æ–¥–Ω–æ–π_—Ñ–∞–π–ª.my> <–≤—ã—Ö–æ–¥–Ω–æ–π_—Ñ–∞–π–ª.asm>")
        sys.exit(1)

    source_path = sys.argv[1]
    output_path = sys.argv[2]
    compile_source(source_path, output_path)
